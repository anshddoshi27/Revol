# Tithi Codebase Baseline Report
Frontend Overview and API Integration Points

Onboarding Flow: The Tithi frontend implements an 11-step onboarding process (Business info, Website, Location, Team, Branding, Services, Availability, Notifications, Policies, Gift Cards, Payment Setup, and Go Live) to collect all necessary business data
GitHub
GitHub
. Currently, these steps use local context/state to save data (via onboarding.save* functions) and do not call any external API. On the final "Go Live" step, the app generates a new business from the accumulated state and inserts it into a fake in-memory store rather than a database
GitHub
. For example, the code calls businessStore.createBusiness(business) and bootstrapWorkspace(...) with all onboarding inputs to produce a local workspace context
GitHub
. In a real backend scenario, this is where an API call would create the business and related records in the database. We only create the actual business record once onboarding is fully complete (per design) – prior to that the user account exists but no persisted business data is saved.

Admin Views: After onboarding, the owner is taken straight to their business's admin dashboard (no multi-tenant selector since one user = one business). The admin interface mirrors all the configuration pages from onboarding (business settings, team, services, availability, notifications, policies, etc.) so the owner can adjust those parameters in real time post-launch. In addition, the admin has a "Past Bookings" page (the "Money Board") showing all completed or pending appointments, and a Payments & Fees ledger for financial entries
GitHub
. All these admin pages currently rely on the in-memory FakeBusiness context (workspace) for data. For instance, the Past Bookings page renders cards from workspace.bookings and uses a callback to perform actions on bookings in state
GitHub
GitHub
. No real network calls are made – a helper text in the UI even notes that "Preview data is in-memory today. When the backend arrives these components call real endpoints with the same contracts."
GitHub
. This indicates that the frontend is designed to call future API endpoints for these admin features once the backend is implemented.

Past Bookings & Money Board: In the admin's Past Bookings (Money Board) view, each booking is displayed with the customer's name, email, phone and other details. Each booking card provides four action buttons – Completed, No-Show, Cancelled, Refund – which are the only ways that money moves in Tithi. Pressing one of these will eventually trigger a backend operation: e.g. capturing the payment for a completed appointment, charging a no-show or cancellation fee, or issuing a refund. Until one of these actions is taken by the owner, no payment is actually captured from the customer's saved card. The current frontend simulates this by calling performBookingAction in the fake business context, which updates the local booking status and prepares a fake response (including a mock Stripe pay-link for 3D Secure if needed)
GitHub
GitHub
. In the real backend, each of these buttons will call an API endpoint (e.g. POST /api/bookings/{id}/complete, etc.) that uses Stripe to perform the charge or refund and then updates the booking and payment records accordingly. The UI already reflects the expected behavior (disabling buttons, showing toast notifications for success or if action is unavailable)
GitHub
GitHub
, following the rule that nothing is charged at booking time and charges occur only on these button presses.

Public Booking Flow: Tithi provides a public-facing booking site for each business at {subdomain}.tithi.com where customers can self-book appointments without logging in. In the current implementation, this is the /public/[slug] page. The frontend uses the business slug in the URL to load the corresponding business data. Right now, if a business is not already in context, the code can seed a default business (e.g. for demo purposes when slug is "novastudio") by calling loadSeedBusiness()
GitHub
. Once the business and workspace are loaded in context, the PublicBookingExperience component is rendered with that data
GitHub
GitHub
. The public booking flow allows the customer to choose a service (and possibly staff), pick an available time slot, and then enter their contact info and payment details to book. The credit card is collected and tokenized via Stripe (client-side) but not charged immediately – instead, a Setup Intent is used to save the card on file (status becomes "card_saved") and the booking is created with a pending/scheduled status. In the frontend's fake mode, submitting the booking calls recordPublicBooking(payload) which adds a new booking to the in-memory store and stores the card details as saved
GitHub
GitHub
. In the real app, this will correspond to an API call (e.g. POST /api/public/[slug]/book) that creates a customers entry, a bookings row (with status='pending' and payment_status='card_saved'), and a booking_payments record for the saved card (Stripe SetupIntent), all in the database. The public booking page also needs to fetch availability slots – currently, the demo computes slots in the frontend, but in production the backend will generate available time slots based on the stored availability rules, existing bookings, and blackouts (likely via an endpoint like GET /api/public/[slug]/availability?serviceId=X&date=YYYY-MM-DD). Overall, the public flow will rely on backend endpoints to get business info, services, and open slots for the given subdomain, and to create a new booking with Stripe payment setup.

Backend Architecture (Next.js + Supabase)

For v1 of the backend, we will use Next.js Route Handlers (in the apps/web/src/app/api directory) along with Supabase (Postgres) as the database. This means we do not need a separate Express server – we can implement RESTful API routes within the Next.js app, leveraging Supabase's client and libraries for database access and authentication. Each API route will correspond to a specific resource or action, aligning with the frontend's needs. For example, we will have routes for onboarding completion (to create the business and initial data), for CRUD operations on services, staff, availability, etc., for fetching availability slots, for booking creation, and for performing booking actions (capture payment, refund, etc.). These route handlers will run on the server side and can safely use the Supabase Admin client or the authenticated JWT from the user.

Supabase Auth & RLS: We will use Supabase's JWT-based authentication for the owner login. After the owner signs in (via Supabase Auth), the frontend will have an access token which it will include in API requests (Supabase's libraries or a Next middleware can attach it). On the backend, we will configure the database with Row Level Security (RLS) policies so that each query automatically isolates data per user. The Next.js API routes can either use the Supabase JavaScript client (which sends the JWT and respects RLS) or direct SQL queries with the auth.uid() available in the Postgres session. Supabase is a natural fit here since we have "many businesses, each tied to one user," and RLS ensures each API call only returns that owner's rows. In practice, that means every multi-tenant table will have a user_id column and an RLS policy of the form:

USING (user_id = auth.uid() AND deleted_at IS NULL)


ensuring the current user can only see their own active (not soft-deleted) records. We will enable RLS on all such tables and rely on Supabase's JWT auth for identity. This approach aligns with the design choice to use Supabase (JWT + RLS) rather than custom session cookies, giving us a clean security model without building session management ourselves. (Since each owner only ever accesses their one business, the code can trust auth.uid() as the business owner context.)

Next.js Route Structure: We will create route handler files under apps/web/src/app/api. Likely subpaths will include: /api/onboarding/complete (to finalize onboarding), /api/services, /api/staff, /api/availability, /api/notifications, etc., for admin-side updates, as well as /api/public/[slug]/... for public-facing data (like getting services and slots for a given business slug, and posting new bookings). Currently, the repository does not have these API files (our code search found no existing app/api implementations, meaning this is greenfield). We will therefore scaffold these endpoints according to the above resource needs. Each route handler will interact with the Supabase client to perform the necessary DB operations. For example, POST /api/onboarding/complete will insert a new row into the businesses table and all related tables (categories, services, staff, etc.) in one transaction (or sequential calls), using the data gathered in onboarding. Similarly, GET /api/app/bookings (for admin) might fetch all bookings for the authed user's business, or we might have more granular routes (e.g. /api/app/bookings/past vs upcoming). The Next 13 App Router allows us to also use Server Actions for form submissions, but given our need for a clear API surface for the client-side calls (especially from the public site), standard route handlers returning JSON will suffice. We will keep the backend logic in these handlers slim, deferring heavy logic (e.g. slot calculation, Stripe integration calls) to helper modules or the database (via SQL or RPC functions) for clarity.

In summary, the backend will be embedded in the Next.js app using API routes backed by Supabase. We'll use Supabase Postgres for all persistence, with migrations to define the schema, and rely on Supabase Auth for identifying the user in RLS policies. No separate Node server or microservice is introduced at this stage – this keeps deployment and development simpler for v1.

Database Schema Design

Using the "backend clarifications" as a guide, we have finalized the data model and will write the SQL schema accordingly. The core principle is one owner = one business and all other entities link back to the business (and thus to the owner's user_id) for tenancy isolation. Every table that represents tenant-specific data will include a user_id (the owner's UUID from Supabase auth) and a business_id (the primary key of the business) for relational integrity. We will use UUIDs for primary keys across the board. Below is an outline of the main tables we will implement, along with their key columns and relationships (all tables have standard timestamp fields like created_at, updated_at, and most have deleted_at for soft deletes):

Businesses: One row per business (owned by a user). Stores the business's basic info and account status. Key fields include id (UUID PK), user_id (FK to auth.users, unique per business), name (business name), dba_name (doing-business-as name), legal_name, industry, and contact details (phone, support_email, website). It also has the chosen subdomain for the public booking site (must be unique), the timezone, address fields (street, city, state, postal_code, country), branding info (brand_primary_color, brand_secondary_color, logo_url), and billing fields for Tithi and Stripe integration (stripe_connect_account_id for Stripe Connect, stripe_subscription_id for the Tithi subscription, subscription_status which can be 'trial', 'active', 'paused', or 'canceled', plus trial_ends_at and next billing date). We enforce one business per user with a unique index on user_id, and one-of-a-kind subdomains with a unique index on subdomain. This table is the root for all other data; deleting a business (soft delete via deleted_at) effectively archives all its related records (RLS will hide any with a deleted business).

Service Categories: Categories used to group services (for example, "Hair Treatments" vs "Coloring" in a salon). Columns include id (UUID PK), user_id, business_id (FK to businesses), name (category name), optional description, and a display color code for UI use. We also have an integer sort_order to preserve the ordering of categories as configured by the user, and an is_active flag (default true) to allow hiding/deleting categories without losing them. A category business_id must match the business of the given user_id (we will enforce this via application logic or a DB constraint/trigger to avoid cross-tenant mixups). This table has composite indexes like (user_id, sort_order) to quickly fetch all categories for a business in the correct order. Soft-deletion is handled via deleted_at and we ensure RLS filters out any where deleted_at is set.

Services: The actual bookable services offered by the business. Each service belongs to a service_category. Important fields: id (PK), user_id, business_id, category_id (FK to service_categories), name of the service, description (details of the service), duration_min (length of the service in minutes), price_cents (base price in cents), and any pre_appointment_instructions (text shown to the customer before booking). Services also have an is_active flag for hiding or retiring a service. We'll index by (user_id, is_active) to query active services quickly for the catalog. Relationship: each service's business_id must match its category's business and the owner's user_id (again, ensuring everything stays within the tenant). Soft delete via deleted_at as well.

Staff: The staff members or team who can perform the services. Staff here are not separate user accounts; they are data records tied to a business (per earlier decision, staff do not have their own login). Fields: id (PK), user_id, business_id, name (staff member's name), role (e.g. "Stylist", "Therapist" – just for display), color (a color code to represent this staff's calendar entries), and notes (any internal notes about the staff). There's an is_active flag to mark a staff member inactive if they leave (rather than deleting and messing up historical bookings). We will index (user_id, business_id, is_active) to list active staff efficiently. Staff have a foreign key to the business. They can be soft-deleted as well (though usually we'd use is_active).

Staff Services: A join table linking which staff can perform which services. This implements the many-to-many relationship between staff and services (since each service might be offered by certain staff, and each staff can do multiple services). Columns: id (PK), user_id, business_id, staff_id (FK to staff), service_id (FK to services). We add a unique constraint on (staff_id, service_id) so the same staff-service combination isn't entered twice. For fast lookups we'll index by user_id, staff_id and user_id, service_id (useful when querying what services a particular staff offers or which staff offer a given service). This table doesn't need a deleted_at – if a staff no longer offers a service, the row can be removed (or we could treat removal as deletion if we want history, but not necessary).

Availability Rules: This table defines the weekly schedule and exceptions for when each staff can perform each service. It captures the availability that the owner sets in onboarding (step 4) and in the admin. Key fields: id (PK), user_id, business_id, staff_id, service_id – together these identify which staff & service the rule applies to. Then we have the specifics of the rule: a rule_type which can be 'weekly', 'exception', or 'closure'. For weekly recurring availability, we use weekday (0=Sunday through 6=Saturday) and a start_time and end_time (time of day, stored as TIME in the business's timezone). For one-time exceptions or closures, we use a date field (specific calendar date) in combination with rule_type. We also allow a capacity (default 1) in case multiple concurrent bookings per slot are allowed in future. All rules can be soft-deleted via deleted_at. To fetch availability efficiently, we'll index by (user_id, service_id, staff_id, weekday) for weekly rules and (user_id, staff_id, date) for specific exceptions. The backend "slot engine" will use these rules to generate open time slots for booking. Essentially, for each service and each staff, weekly rules provide a template of availability (e.g. Staff A can do Service X on Mondays 9am–5pm), and exceptions can add or remove availability on particular dates (like a closure or an extra working day). We will also implement a separate Blackouts table (see next) for business-wide or staff-specific blocked times.

Blackouts: The blackouts table records time ranges when the business or a specific staff member is unavailable, overriding the normal schedule. Fields: id (PK), user_id, business_id, staff_id (nullable – if null, the blackout applies to the entire business, i.e. all staff/services), start_at and end_at (timestamps for the blackout period), and a reason (text note, e.g. "Vacation" or "Closed for maintenance"). Blackouts effectively subtract from availability: when generating slots, any times that fall within a blackout window (for that staff or global) will be excluded. This helps model vacations, holidays, or other closures. We will index by user_id and staff_id as needed for quickly finding relevant blackouts. Blackouts can simply be hard-deleted or we might include deleted_at if we want to keep a record of past blackouts for audit.

Customers: When a customer books an appointment via the public flow, we capture their basic info in a customers table. Columns: id (PK), user_id, business_id, name (customer's name), email, and phone number. We also store a stripe_customer_id if we choose to create a Customer object in Stripe (this would allow us to attach multiple payment methods or look up their payment history in Stripe). This table lets the business owner see repeat customers and contact info. We will put a unique index on (user_id, email) and (user_id, phone) since an owner typically shouldn't have duplicate customers with the same email/phone – though customers aren't logging in, it's useful for preventing exact duplicates. We'll also index by name for admin search functionality. (Note: It's possible that two different businesses could have customers with the same email, which is fine since user_id is different, and RLS will isolate them.)

Bookings: The appointments or bookings table is a critical centerpiece of the system. Each booking ties together a customer, a service, a staff member, a time slot, and payment info. Key columns include: id (UUID PK), user_id, business_id, customer_id (FK to customers table), service_id (FK), staff_id (FK). The status of the booking is an enum booking_status – it starts as 'pending' (or 'scheduled') when created and later transitions to 'completed', 'no_show', 'cancelled', or 'refunded' depending on the money board actions. We store the scheduled time in start_at (UTC timestamp) and end_at, plus duration_min (for quick reference of how long the booking is). The booking also stores the pricing: price_cents is the base price at time of booking, and final_price_cents is the price after any discount (e.g. if a gift card or promo code was applied). If a gift card was used, gift_card_id (FK to gift_cards) is set along with gift_card_amount_applied_cents (how much value was deducted from the gift card). We also include a JSONB policy_snapshot of the business's policies at the time of booking. This snapshot stores the exact text of cancellation/no-show policies and the fee percentages in effect – preserving this prevents disputes if policies change later. Furthermore, we capture the customer's consent timestamp and the IP/user-agent from which they checked "I agree" to the policies (consent_at, consent_ip, consent_user_agent) for legal compliance. Booking also has a source field to note if it was created via 'public' booking page or an 'admin' (manual) booking. For payment tracking, we include payment_status (another enum) and last_money_action (enum of last action taken) as denormalized summary fields on the booking. For example, initially payment_status='card_saved' and last_money_action='none', then if the owner presses "Completed", the payment_status might become 'charged' and last_money_action 'completed_charge'. These help display state in the UI without always aggregating from payments. We will index the bookings table for the common query patterns: by date and status. For instance, an index on (user_id, status, start_at DESC) will help fetch past bookings or upcoming bookings sorted by time, and (user_id, customer_id, start_at DESC) helps to list bookings for a particular customer. We will also enforce that two active bookings don't overlap for the same staff and time. This can be done by a partial unique index: UNIQUE (staff_id, start_at) WHERE status IN ('pending','scheduled') to prevent double-booking the same slot. (This corresponds to ensuring no overlapping bookings for a staff – as noted, the slot generator will also ensure it.) Bookings are generally not soft-deleted (we keep history; if needed, we might only soft-delete as part of a complete business deletion for GDPR).

Booking Payments: This table records each financial transaction or authorization associated with a booking. Every booking will have at least one associated payment record (the initial card save), and may have more (capture charges, fees, refunds). Fields: id (PK), user_id, business_id, booking_id (FK to bookings). For Stripe integration we store the relevant Stripe IDs: stripe_setup_intent_id (for the initial card save at booking time), stripe_payment_intent_id for an actual charge or refund, and possibly a last_payment_intent_id to track the most recent Stripe PaymentIntent for convenience. We record the amount_cents of the transaction (e.g. amount captured or refunded), and a money_action enum to indicate why this payment record exists: was it a 'completed_charge', a 'no_show_fee', a 'cancel_fee', or a 'refund'?. We also set the status (another enum similar to payment status: e.g. 'card_saved', 'charge_pending', 'charged', 'refunded', 'failed') for that transaction. Additionally, for accounting, we include application_fee_cents (the platform's 1% cut) and stripe_fee_cents (Stripe's fee) and net_amount_cents (net payout to the business) – these would be filled in once the charge is completed and we receive fee information from Stripe. The combination of booking_payments rows for a booking tell the full story of money flow. For example, when a customer enters their card, we create a booking_payment with status 'card_saved' and the SetupIntent ID. When the owner later clicks "Completed", we create a new booking_payment row with money_action='completed_charge', amount equal to the final price, and status 'charged' once successful. If they click "No-Show", we create a row with money_action='no_show_fee' and amount equal to the fee (which could be 0). Refunds similarly create a row with money_action='refund' and status 'refunded'. Each time, we also update the parent booking's payment_status and last_money_action to reflect the latest overall state. We enforce uniqueness on stripe_payment_intent_id so we don't accidentally duplicate the same Stripe event. We'll index booking_payments by (user_id, booking_id) to retrieve all payments for a given booking, and by (user_id, created_at DESC) to list recent transactions (for the ledger page). This table, along with bookings, is central to the Money Board and Payments admin views, allowing the owner to see what has been authorized, captured, or refunded.

Business Policies: This table (sometimes called policies or business_policies) stores the configurable policy texts and fee settings that the owner sets in onboarding step 7 (and can edit in admin). Rather than updating in place, we will version the policies so that changes can be tracked. Columns: id (PK), user_id, business_id, version (integer), and the various policy fields: cancellation_policy_text, no_show_policy_text, refund_policy_text, cash_policy_text (free-form text that is shown to customers). Along with each policy text, there are numeric fee settings: for No-Show and Cancellation fees, the owner can choose a flat amount or percentage. So we have no_show_fee_type (discount_type enum, 'amount' or 'percent'), and either no_show_fee_amount_cents or no_show_fee_percent (a numeric percentage up to two decimals). Likewise cancel_fee_type and cancel_fee_amount_cents/cancel_fee_percent for cancellation fees. (If these values are zero or type is 'amount' with 0, it means no fee.) We also keep an is_active boolean – when a new version is created, we might mark the old version as not active. In general, the latest version with is_active=true is the current policy in effect. When a booking is made, we copy the active policy's texts and fee values into the booking's policy_snapshot JSON. This ensures that if the owner updates their policies later, existing bookings still refer to what the customer agreed to. We will index the policies table by (user_id, business_id, is_active, version DESC) so we can quickly grab the current policy or history. Typically, only one row per business is active (the current policies). There's no need for soft delete here (we can just set inactive if replaced).

Gift Cards: This table holds gift card codes or discount codes that the business can generate (onboarding step 8, or later in admin). Each gift card has a unique code and a value, either a fixed amount or a percentage discount. Columns: id (PK), user_id, business_id, code (text code, likely auto-generated string), discount_type (enum 'amount' or 'percent' indicating the type of gift card), initial_amount_cents (for amount-type cards, the starting balance in cents), and current_balance_cents (remaining balance, for amount cards). For percent-type cards, instead of a balance we have percent_off (e.g. 25.00 means 25% off). We also allow an expires_at timestamp for expiration date (optional), and is_active flag to disable a code. We will enforce that each code is unique per business – a unique index on (user_id, code) so that two businesses could coincidentally use the same code string, but one business can't have duplicates. We'll index by code for lookup when a customer enters a gift code at checkout, and by expires_at to help purge or list expired cards. Gift cards can be soft-deleted (or just toggled inactive). When a gift card is applied to a booking, the bookings.gift_card_id is set and the gift card's current_balance is reduced accordingly; if it's a percent card, it can be reused multiple times until expiration (so balance might not apply).

Gift Card Ledger: Every change to a gift card's balance is recorded here for audit purposes. This table logs gift card transactions such as purchases, redemptions, and refunds. Fields: id (PK), user_id, business_id, gift_card_id (FK to gift_cards), and optionally booking_id if the change was associated with a booking (e.g. a redemption or a refund on a booking). The main field is delta_cents – a positive or negative integer indicating how the balance changed. For example, selling a gift card might be +$50 to balance (though initial issuance could also be handled differently), applying a gift card to a booking could be -$30, a refund back onto a gift card could be +$30. We also have a text reason field to categorize the change, e.g. 'purchase', 'redemption', 'refund_restore', or 'admin_adjust'. Timestamp created_at records when the change happened. We will index ledger entries by gift_card and date (user_id, gift_card_id, created_at) for chronological history per card. This table helps in reconciliation and in potentially showing gift card usage history in the admin UI.

Notification Templates: Tithi allows owners to set up custom notification templates (onboarding step 6) for various events (booking confirmation, reminders, etc.). The notification_templates table stores these configurations. Columns: id (PK), user_id, business_id, name (an internal label for the template, e.g. "Follow-up Email 1"), channel (enum notification_channel: 'email' or 'sms' – push notifications could be included but likely not in v1), category (enum notification_category: e.g. 'confirmation', 'reminder', 'follow_up', 'cancellation', 'reschedule'), and trigger (enum notification_trigger: e.g. 'booking_created', 'booking_confirmed', 'reminder_24h', 'reminder_1h', 'booking_cancelled', 'booking_rescheduled', 'booking_completed', etc.). These define when the notification is sent. We also store the actual content: for emails, a subject line, and for all channels, a body_markdown which can include placeholders like ${customer.name} etc.. (Placeholders supported might include customer name, service name, service price, booking date/time, business name, booking URL, etc.. The backend will substitute these when sending.) Each template has an is_enabled flag to allow the owner to turn off a notification without deleting it. We include soft-delete deleted_at as well in case they remove a template. Indexes will be on (user_id, trigger, is_enabled) to quickly find the active template(s) for a given event, and perhaps (user_id, category) if needed. In use, when a triggering event occurs (e.g. a booking is created), the system will find the corresponding template for that owner's business (if any) and generate a notification job from it.

Notification Events: This table logs each notification sent or attempted, primarily for record-keeping and debugging. Columns: id (PK), user_id, business_id, booking_id (nullable, the notification might relate to a specific booking), template_id (nullable if it was a system-triggered message without a template, but usually corresponds to a notification_template), channel ('email' or 'sms'), to_address (the email or phone number it was sent to), status (text status: e.g. 'queued', 'sent', 'failed'), provider_message_id (ID from the email/SMS provider, if available), error_message (if failed), and sent_at timestamp for when it was successfully sent (or null if not yet sent). We'll index by (user_id, booking_id) to find all notifications related to a booking, and by (user_id, to_address, created_at DESC) in case we need to search logs for a particular recipient. This table will be written by the notification sending logic (each attempt produces an event, especially if using an outbox/job system).

Notification Jobs (Background Jobs): To actually send notifications (emails/SMS) asynchronously, we will use a jobs table (e.g. call it notification_jobs). This table will queue outgoing messages so that a worker or cron can send them and mark them done. Fields likely include: id (PK), template_id (FK to notification_templates that spawned it, if applicable), business_id and user_id (though user_id can be inferred via business, we may still include for RLS), the recipient info (recipient_email or recipient_phone depending on channel), the subject (for email), the body content (already rendered with placeholders), and the channel ('email'/'sms'). It will also have a status for the job (e.g. 'pending', 'in_progress', 'sent', 'failed', 'dead'), an attempt_count (how many times tried) and maybe last_error message if failed. We'll also have scheduled_at to support scheduling (for reminders that should send at a future time). The system processing these jobs will implement retry with exponential backoff: e.g. wait 5 minutes after 1st failure, 15 after 2nd, and give up (mark dead) after 3rd. A unique constraint like (booking_id, trigger, channel) could serve as an idempotency key to avoid duplicate notifications for the same event. The jobs table helps ensure reliability and that notification sending can be monitored (we could even surface failed notifications in an admin tool). This table will have RLS (only the owner can see their own jobs), but the actual sending process might run with admin/service role to update statuses.

Idempotency Keys (helper table): We may introduce an idempotency_keys table to safely handle external requests or repeated actions. This table would store a unique key (e.g. a GUID or a combination of request parameters) and perhaps a timestamp, to ensure that if the frontend or an external webhook calls the same endpoint twice (due to timeout or retry), we do not perform the action twice. In the context of payments, when we handle webhooks or booking actions, using an idempotency key is recommended. The design doc explicitly suggests an idempotency key mechanism as optional. We can implement a simple table with idempotency_key (PK), user_id (or maybe no user_id if for public webhooks), and created_at. Before processing a potentially duplicate-sensitive request, we insert a row with a generated key; if the insert fails (key exists), we know the request was already handled. We will include this in our schema for completeness, although it's an optional safety net.

Enumerated Types: We will use Postgres ENUM types to represent several status fields and types, for clarity and consistency. The schema will create the following enum types with these values (as gleaned from the design):

booking_status: 'pending', 'scheduled', 'completed', 'no_show', 'cancelled', 'refunded' – indicates the state of a booking.

payment_status: 'none', 'card_saved', 'charge_pending', 'charged', 'refunded', 'failed' – state of a payment or booking's payment overall.

money_action: 'none', 'completed_charge', 'no_show_fee', 'cancel_fee', 'refund' – labels the type of financial action taken.

notification_channel: 'email', 'sms'.

notification_category: 'confirmation', 'reminder', 'follow_up', 'cancellation', 'reschedule' (as used for template grouping).

notification_trigger: 'booking_created', 'booking_confirmed', 'reminder_24h', 'reminder_1h', 'booking_cancelled', 'booking_rescheduled', 'booking_completed'.

discount_type: 'amount', 'percent' – used for gift cards and policy fee types.

These enums will be defined in the migration before creating any table that uses them.

Constraints & Indexes: In addition to the unique constraints and indexes mentioned with each table above, we highlight a few important ones: we will enforce Unique owner for businesses (each businesses.user_id must be unique), Unique subdomain for businesses, Unique gift card code per business, Unique staff-service pair in the junction table, and Unique Stripe payment intent ID in booking_payments to avoid processing duplicates. As noted, we'll also implement a partial unique index on bookings (staff_id, start_at) for active statuses to prevent double-booking a staff at the same time (ensuring no overlapping bookings) – this wasn't explicitly listed in the text, but it aligns with the requirement that the slot engine and booking logic avoid overlaps.

Performance-wise, we follow the recommended index strategy: every table will have an index on user_id to optimize RLS permission checks and tenant-scoped queries. Time-series tables like bookings, booking_payments, and notification_events will be indexed by date (e.g. start_at DESC or created_at DESC) for efficient retrieval of recent items. Lookup fields such as customer email/phone and gift card code will be indexed as well. And for availability, composite indexes on service/staff/weekday expedite slot generation queries. All these indexes and constraints will be declared in the migration SQL.

Row-Level Security Policies

Every tenant-owned table in the schema will have Row-Level Security enabled and a policy to allow only the owner to access their data. We will add a user_id UUID column to each of these tables (as described above) and link it to the Supabase auth user. The RLS policy pattern (using Supabase's typical approach) will be:

ALTER TABLE <table_name> ENABLE ROW LEVEL SECURITY;

CREATE POLICY "user_is_owner" ON <table_name>
USING (user_id = auth.uid() AND (<table_name>.deleted_at IS NULL OR <table_name>.deleted_at IS NULL));


In practice, we adjust the condition to include deleted_at IS NULL only for tables that have soft deletes. For example, on services, staff, service_categories, etc., we include AND deleted_at IS NULL so that soft-deleted entries are hidden from normal queries. For tables without a deleted_at (like booking_payments or the join tables), the policy is just user_id = auth.uid(). These policies mean that even if a query accidentally misses a filter by business or user, the database will not return rows belonging to another user. It's a crucial safety net against multi-tenant data leaks. We will create these policies for all relevant tables: businesses, service_categories, services, staff, staff_services, availability_rules, blackouts, customers, bookings, booking_payments, policies, gift_cards, gift_card_ledger, notification_templates, notification_events, notification_jobs, etc. Supabase's Auth will ensure that auth.uid() is set to the owner's user ID when they call the APIs with their JWT. (We will also ensure the Supabase JWT is passed to Postgres in our route handlers; if using the Supabase JS client on the backend, this is handled automatically when we initialize it with the user's access token.)

Additionally, some tables may have more nuanced RLS rules for public access. For instance, the public availability endpoints might allow read-only access to certain data (services, slots) without a user token. In those cases, we might create a separate Supabase role or use an anon key with carefully crafted policies (e.g. allow read access to services and availability where business_id matches a provided subdomain and maybe using a security definer function). But since each booking site is public, we likely will create a safe RPC function or a special policy to allow selecting necessary fields from certain tables by subdomain without auth, while still preventing cross-business data leakage. This is something to consider (Supabase supports policies for anon role separately). For now, we assume the simpler path: the Next.js public API route can use a Supabase service role to query the needed data for a given subdomain, and we'll ensure in code it filters by that business's ID.

Migrations and Next Steps

We will codify the above schema in SQL migration files (under supabase/migrations). The migration will do the following in order:

Create ENUM types – booking_status, payment_status, money_action, notification_channel, notification_category, notification_trigger, discount_type – with the values listed earlier. This must happen first so that tables can use these types.

Create tables in a dependency-aware sequence. Based on our model, we'll create the tables in roughly this order (to satisfy foreign key references without temporary errors): businesses first, then service_categories, services, staff, staff_services, availability_rules, blackouts, customers, bookings, booking_payments, policies, gift_cards, gift_card_ledger, notification_templates, notification_events, notification_jobs, and helper tables like idempotency_keys. This order ensures that, for example, services can reference categories, bookings can reference customers/services/staff which are created earlier, etc. Each CREATE TABLE statement will include the columns and constraints as described (primary keys, foreign keys, unique constraints, default values, etc.).

Add indexes – for each table we will add the indexes discussed (if not already created inline with the table definition). For instance, indexes on user_id for all tables, composite indexes on bookings and others as needed, unique indexes on certain fields, and the partial index on bookings for active slots.

Enable RLS and create policies – After creating the tables, we will execute ALTER TABLE ... ENABLE ROW LEVEL SECURITY on each, and then CREATE POLICY ... USING (user_id = auth.uid() AND deleted_at IS NULL) as appropriate. We'll do this for all tenant tables in the same migration (or a separate one immediately after).

Seed or reference data – If Supabase requires any initial setup (like inserting some reference data or configuring auth settings), we will handle that. But most likely, we will rely on Supabase's default (the auth.users table is managed by Supabase when users sign up, and our schema references that).

Once the migration SQL is written, we will run it using the Supabase CLI or the project's migration runner. We will apply these migrations in our development environment and verify that the database is structured correctly (no errors on creation). We expect the Supabase local instance to now have all the tables and enums. We should test a few basic queries to ensure RLS is working (Supabase provides a way to simulate the user context).

With the schema in place, the next steps will be to integrate the backend with the frontend:

Hook up the onboarding form to call an API route that creates the business and all related records (services, staff, etc.) in these tables once the user finishes the steps.

Update the admin pages to fetch data from the database via the API routes (for example, load services list, staff list, etc., from /api/ endpoints instead of using the fake context).

Implement the booking flow backend: an endpoint to retrieve available slots (using the availability_rules and blackouts data with a slot-generation algorithm on the fly or via a stored procedure) and an endpoint to create a booking (inserting into customers, bookings, booking_payments in a transaction).

Implement Stripe integration in the backend (creating Connect accounts for businesses, handling Setup Intents and Payment Intents). The schema already has fields to store Stripe IDs and fees, so we will make use of those when integrating (e.g., set stripe_connect_account_id in businesses when onboarding the owner's payout account, store stripe_payment_intent_id when capturing a charge, etc.).

Implement the notification scheduling: when certain triggers happen (booking created, etc.), insert jobs into notification_jobs and have a worker or cron (outside Next.js, maybe using Supabase Edge Functions or a lightweight server) process those jobs and send emails/SMS. The sending results then populate notification_events.

Finally, we will thoroughly test the migrations by running them locally using the Supabase CLI. After applying, we'll perform test queries (maybe via pgAdmin or Supabase studio) to ensure that RLS policies are correctly restricting data (e.g., selecting from services as one user only yields that user's rows). We will also test inserting sample data and ensure the constraints (like unique subdomain, no overlapping booking) behave as expected.

By following this plan, we establish a complete baseline for the backend: a clearly defined database schema with all necessary tables and relations, secured by RLS, and accessible through Next.js API endpoints. This will fulfill the frontend's data needs for onboarding, admin management, public booking, and the money board, aligning the implementation with the design specifications and the current frontend architecture.




